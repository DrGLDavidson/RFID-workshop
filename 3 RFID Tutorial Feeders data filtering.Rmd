---
title: "3. RFID Tutorial: Introduction to RFID data filtering"
author: "Gabrielle Davidson"
date: "2024-08-12"
output: html_document
---
## 1. Get set up

### Open R Studio

### Check R packages installed
```{r echo=T, results='hide', error=FALSE, warning=FALSE, message=FALSE}
#load the following packages
library(tidyverse)
library(rmarkdown)
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(stringi) #may not need this
library(magrittr) #may not need this

```
### Download resources necessary for the workshop
Download the resources from **[my github page](https://github.com/DrGLDavidson/TOBEUPDATED)**

## 3.1 import your dataset to your environment from your working directory. 

```{r}

#clear the global environment so we don't have any conflicts with the next steps 

rm(list = ls(all.names = TRUE))

#choose the appropriate working directory

setwd("F:/RWorkspace/GitHub/RFID-workshop/data")

#call your most recent dataset of merged feeder data. 

df<-read.delim("Masterdf_220209.txt", header=TRUE)
head(df)
names(df)

```

## 3.2 Data filtering

### 3.2.1 Remove misreads (i.e. erroneous TagID_hex values)
# Ocassionally the RFID reader will incorrectly read an tag. This may be because the bird does not properly land on the perch to feed, and so these 'misreads' can be removed. 
# To remove misreads, we need to match the feeder data against known tagged bird IDs (i.e. Passive Integrative Transponder (PIT) tag numbers, aka TagID_hex). I have provided a file with a list of PIT tags and corresponding metadata (species, age, sex etc.). Note this data is NOT from the UEA population. 

```{r}

#upload a list of your known PIT tag IDs. Notice that the file is a .csv, rather than .txt
PIT<-read.csv(file="PITList_tutorial.csv", header=TRUE)
names(PIT)

#note that the ring type (BTO and PIT) refer to whether it was a new bird (first time given the ring), or retrap (already had the ring). It is possible that a bird may already have a BTO ring (R) but not a PIT tag (N). However, in these cases, the code was meant to be A for added (but you can ignore this detail for now). 

#check how many unique PIT tag IDs there are, it should match the number of observations (global environment). If it does not match, it suggests duplicates. Duplicates would matter if you are planning to merge the metadata and you want it to be a particular date (e.g. age of a bird when it was first fitted with a ring)

length(unique(PIT$pitID))

#to merge/match PIT tags from two files you must ensure the header that contains the values of interest are named the same across files. Currently they are not. 

head(PIT)
head(df)

#rename the header in PIT to match that of df
names(PIT)[names(PIT) == "pitID"] <- "TagID_hex"  
names(PIT)

#if we view df, we will also see there are a lot of rows with no TagID_hex. This is because non-tagged birds often land on the feeder and it shows up as a time stamp with no corresponding TagID_hex. Lets remove blank rows, otherwise there will be many rows that can't merge with PIT. 

df <- with(df, df[!(TagID_hex == "" | is.na(TagID_hex)), ])

#Now you can merge dataframes by their shared TagID_hex value. In addition, if there are any missing TagID_hex values from PIT, it will be indicated with "NA". In other words, if a bird that is not on our database was detected at the feeder, it will show up as NA. This code also returns any values from our PIT dataframe that was not on df. In otherwords, an NA is given if the bird on our database was never detected at the feeders. 

df1 <- merge(df, PIT, by = "TagID_hex", all = TRUE)
df1[is.na(df1)] <- "NA"  

#We are only interested in the TagID_hex that was detected at the feeder, but not on our database. We will filter these into a new dataframe called missing. We extract these as values that did not have a BTO 

missing<-df1%>%
  filter(btoID=="NA")

# why do we do this with the header btoRing? Because TagID_hex is now merged across dataframes, so this is no longer informative for missing data. Any of the headers from the PIT dataframe would work, but we are using btoID. 

#there are 54 observations where there is no corresponding PIT tag. 
#create a list of TagID_hex reads that did not have a match: 

uniqueMisreads <- unique(missing$TagID_hex)
uniqueMisreads

#there are two tags. "0300024FEF" is our reference tag. It is the tag that the experimenter uses to test the feeders and mark when experiments start and end. "01103F3B1B" looks like a genuine tag. But is it a misread or missing data from our PIT tag data? To answer this, double check the master ringing database to see if that tag is there. If it is not there, assume it is a misread. If it is there, add it to the PIT database and re-run your code.

#save your misreads for your records

setwd(path)  # insert the correct working directory (path)

write.csv(uniqueMisreads, file="uniqueMisreadsFeeders.csv")

#assuming we have resolved this, merge df and PIT again, using a different code that wont keep all NAs from the PIT file, but will remove NAs from the btoRing column, using the argument all = FALSE

df1 <- merge(df, PIT, by = "TagID_hex", all = FALSE)

#this returns a dataframe that is 1214 observations. 
1268-1214

# this equals 54, which is the same number of observations from our dataframe "missing". This makes sense. 

# Another way you can merge dataframes is using the package dplyr and the following code: 

df2<-left_join(df, PIT ,by ="TagID_hex")

# and then we have to remove NAs with another chunk of code

df2<-df2[!is.na(df2$btoRing),]

write.table(df2, file = "Masterdf_noMisreads.txt",sep="\t",row.names=FALSE) 

#clear the global environment so we don't have any conflicts with the next steps 

rm(list = ls(all.names = TRUE))

```

### 3.2.1 Filter repetitive RFID reads within a single visit

## A common goal in quantifying bird behaviour is to extract the number of visits a bird makes to a feeder. Due to the nature of the RFID device, multiple rows will be recorded if the bird sits on the perch while feeding, yet this should be considered a single visit.  

```{r}
#As we will be working with time, we need to check how our dataframe is named and organised
df2<-read.delim("Masterdf_noMisreads.txt", header=TRUE)

head(df2)

#there are two separate date columns and a time column. This is because we merged the feeder data with ringing data. 

#rename ringing columns

names(df2)[names(df2) == "date"] <- "dateRinged" 
names(df2)[names(df2) == "time"] <- "timeRinged" 

#rename feeder date column to indicate it also includes hours, minutes and seconds

names(df2)[names(df2) == "Date"] <- "dateTime" 

names(df2)

#create a new column with the date only

df2$date<-date(df2$dateTime)

#cleanup the dataframe by selected the columns and order we want them to appear

df2<-df2%>%
  select(date, dateTime, Hmsec, ID, Event, Channel, Dur, Clks, Freq, Edges, Reps, Type, TagID_hex, feeder, dateRinged, timeRinged, btoRingType, btoID, species, pitTYPE, age, sex, wing, weight)
names(df2)

#we need to change the class of the timeDate column as a POSIX class. 

df3<-df2%>%
  mutate(dateTime=ymd_hms(dateTime))

class(df3$dateTime)

```
```{r, warning=FALSE}
#create a column that calculates the time difference with previous row of a dataframe grouped by date, feeder and RFID

#consider why you are grouping by these columns. The time interval will only be calculated PER date PER feeder and PER tag. If you wanted to know the time interval between days as well, then you would not group by date. Or if you wanted an interval regardless or feeder, you would remove feeder from your grouping argument. 

df4<-df3 %>%
  arrange(dateTime)%>%
  group_by(date, feeder, TagID_hex) %>% 
  mutate(timeSincePreviousVisit = dateTime - lag(dateTime))%>%
  arrange(TagID_hex, feeder, dateTime)%>%
  ungroup()%>%
  select(feeder, TagID_hex,date, dateTime, timeSincePreviousVisit)

#look at the output of just those selected columns to see we have produced what we think we want
View(df4)
#0 sec was calculated if the bird was on the feeder within the same seconds
#NA is given if it is the birds' first visit to feeder X for that date

#rerun the above code without the select() argument so we have the full dataframe of variables

df4<-df3 %>%
  arrange(dateTime)%>%
  group_by(date, feeder, TagID_hex) %>% 
  mutate(timeSincePreviousVisit = dateTime - lag(dateTime))%>%
  arrange(TagID_hex, feeder, dateTime)%>%
  ungroup()


#the new column timeSincePreviousVisit has "secs" and we don't want that, so lets remove it

df4$timeSincePreviousVisit <- gsub(' secs', '', df4$timeSincePreviousVisit)

#the column timeSincePreviousVisit needs to be numeric for graphical purposes and for filtering based on greater than/less than values

df4$timeSincePreviousVisit <- as.numeric(as.character(df4$timeSincePreviousVisit)) 
class(df4$timeSincePreviousVisit)

#create a dataframe of successive visits that are less than 20 seconds so we can graph how frequently birds are read at the feeder
#use the "select" argument to extract only the column named timesSincePreviousVisit
df5<-df4%>%
  filter(timeSincePreviousVisit <=20)%>%
  select(timeSincePreviousVisit)
class(df5$timeSincePreviousVisit)


#cumulative frequency graph
ggplot(df5, aes(timeSincePreviousVisit, y= 1-..y..))+
  stat_ecdf(geom = "step", color="purple")
#histogram
ggplot(df5, aes(x=timeSincePreviousVisit)) +geom_histogram(binwidth = 1) 

#it appears that visit frequency drops after 2 seconds, but it is not a clear drop.

#Most of the literature does a cut off at 2 or 3 seconds. 

#Filter dataset to remove visits that were within 2 seconds of eachother

#note that there are NAs because it was the first visit of the dataframe so we can replace that with 'firstVisit'
df4$timeSincePreviousVisit[is.na(df4$timeSincePreviousVisit)] <- 'firstVisit' 

#to ensure we do not loose these visits - i think???? NO THIS JUST DUPLICATES DATA
#df6<-df4%>%
  #filter(timeSincePreviousVisit=='firstVisit')

df6<-df4%>%
  filter(timeSincePreviousVisit>2)
#we need to make the column timeSincePreviousVisit a character back from numerical in order to bind with df5, which is a character string
df6$timeSincePreviousVisit <- as.character(df6$timeSincePreviousVisit)

df7<-bind_rows(df6)%>%
  arrange(dateTime, TagID_hex,feeder)
view(df7)


write.table(df7, file = "Masterdf_noRepeats.txt",sep="\t",row.names=FALSE)

rm(list = ls(all.names = TRUE))

```

### 4.4 Checking for RFID malfunction. In otherwords, periods of missing data.

```{r}

df1<-read.delim("Masterdf_noRepeats.txt", header=TRUE)

#Check for periods of missing data
#we have a dataframe with time since previous visit grouped by individual and by date. We would expect big time gaps across all individuals if a feeder was down. 

#make dateTime a PosiX class object
df1<-df1%>%
  mutate(dateTime=ymd_hms(dateTime))

class(df1$dateTime)

#plot a histogram of visit frequency over hours. I think days of week is just assigned to start on friday. 
hist(df1$dateTime, breaks = "hours", plot = TRUE, freq = TRUE, format)

#We see there are periods of inactivity but that is regular and likely corresponds to nightime hours. 

#however, this plot does not indicate whether a given feeder was inactive, as it lumps all three feeders together. 

#create new dataframes filtered by feeder. 

F01<-df1%>%
  filter(feeder=='F01')

#plot a histogram of visit frequency over hours for feeder F01
hist(F01$dateTime, breaks = "hours", plot = TRUE, freq = TRUE, format, ylim=c(1, 40) ) #ylim is set because I already visualised all the plots and chose to standardise the y axis so they are comparable. You will have to edit this for your own data. 

F02<-df1%>%
  filter(feeder=='F02')

#plot a histogram of visit frequency over hours for feeder F02
hist(F02$dateTime, breaks = "hours", plot = TRUE, freq = TRUE, format, ylim=c(1, 40))

F03<-df1%>%
  filter(feeder=='F03')

#plot a histogram of visit frequency over hours for feeder F03
hist(F03$dateTime, breaks = "hours", plot = TRUE, freq = TRUE, format, ylim=c(1, 40))

```
These three feeders have very different distributions of visits, and so this is very suspicious. But there doesn't seem to be a specific day where feeders are entirely down, except perhaps the first day of the series on F03. 

You will need to consider your experimental design and what is expected. In fact this data is from feeders that contained different food types and one feeder was only available for a short time period compared to the others. 

### 4.5 Removing periods of missing data.
## If one of the feeders malfunctioned for a day and the entire experiment depends on all feeders working in tandem, this may be good reason to remove data for this day, but see below. 
```{r}
#first check the dates data was collected
unique(df1$date)
#assuming feeder03 had a malfunction on the first day (2022-02-04), remove rows that meet the conditions of having the following dates in the column "date"
df2<-df1[!(df1$date=="2022-02-04") ,]
#the date should no longer be in the dataframe
unique(df2$date)

#if you needed to remove multiple date, the syntax is as follows:

df3<-df1[!(df1$date=="2022-02-04" |df1$date=="2022-02-05" |df1$date=="2022-02-06" ),]
unique(df3$date)
```

How to deal with missing data depends on the experiment and analysis. 

Examples:

- For social network analysis, the Machine Learning algorithms workout flocking events from the streams of data over periods of weeks and therefore these analyses are less sensitive to malfunctions, provided you have sufficient periods when the feeders are working

- If you were calculating frequency of nestbox visits per day, and the device failed part of the day, then you would consider not including it that day, or correcting for malfunction time (e.g. frequncy per hour, not by day, or corrected for hours working)

- If you had a learning experiment where birds had access to one out of an array of feeders, for example, [Reichert et al 2020](https://doi.org/10.1098/rsos.192107), they retained data and added a co-variable for feeder malfunction (assigned, not assigned) in their statistical analyses. 
*We therefore included the duration of feeder malfunction before the bird reached learning criterion for both the assigned (own) feeder and separately for any of the other feeders in that site as additional fixed effects.*

An alternative approach would be to add a column for each feeder and indicate whether it had malfunctioned for each row. 
```{r }

#create a new dataframe where it indicates that feeder 03 malfunctioned. 
df4<-df1%>%
  mutate(feeder03Malf = case_when(date =='2022-02-04' ~'Y', 
                                  date =='2022-02-05'~'Y' , 
                                  date =='2022-02-06'~'Y'))


```


# END OF 3. RFID Tutorial: Introduction to RFID data filtering

```{r}
sessionInfo()
```

