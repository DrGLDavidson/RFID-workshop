---
title: "2. RFID Tutorial: Introduction to RFID use and data handling"
author: "Gabrielle Davidson"
date: "2024-08-12"
output: html_document
---
## 1. Get set up

### Open R Studio

### Check R packages installed
```{r echo=T, results='hide', error=FALSE, warning=FALSE, message=FALSE}
#load the following packages
library(tidyverse)
library(rmarkdown)
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(stringi) #may not need this
library(magrittr) #may not need this

```
### Download resources necessary for the workshop
Download the resources from **[my github page](https://github.com/DrGLDavidson/TOBEUPDATED)**

## 2.1 Introduction to RFID for animal behaviour

**Considerations when designing RFID devices:** 

- Positioning of the RFID antenna (e.g. perch, see [The Open Feeder](https://doi.org/10.1111/2041-210X.13931) for 3D printer file). At UEA we use "Selective Feeders" designed by Nature Counters (Dominic Goodwin), who has troubleshooted the positioning of the perch.

- Power – car batteries, AA batteries, solar pannel. Temperature is going to affect power draw. At UEA we use "Selective Feeders" designed by Nature Counters (Dominic Goodwin), which takes 5 AA batteries.  

- How many times RFID sends a signal and times when it’s dormant. Secondary detection method with low power that initiates RFID. Nature Counters use a strain gauge on the perch to initiate the RFID. Nestboxes use photodiodes to initiate the RFID. 

- Water ingress.

- Squirrels, cattle, people etc.  

**Saving data in the field:** 

Depending on your RFID output, you'll likely have information on what RFID device the data comes from. If it doesn't, or even if it does, devices are mobile, so you must keep good records of where that device was located at the time of data collection and name your file/folder accordingly.  

- Have a naming system for your RFID equipment and data storage device (e.g. SD card) and write it on outside of these devices, and name them electronically within them. 

- Depending on your RFID equipment, you may require a laptop on site to download data from the device, or to deploy/initiate the program/change the program settings/update the time and date. Ideal scenario is a display where this can be edited manually (e.g. time/date), and data storage that can be swapped out (e.g. SD card) so you don't need to carry a laptop. 

- I encourage you to keep a written notebook in the field to write time/date every time an RFID device is deployed, the name of the SD card notebook in the field when it was deployed and when it was removed 

- If you come to a device to see that it has failed, make a log of this. Determining whether a device failed from the RFID visits is not a very reliable method to know if it failed or not because it could be because birds weren't visiting for example. Ideally a firmware program that has additional data files that have performance-based output (e.g. RFID signal, battery power) can allow you to know for sure when failures occurred and why. 
We suggest a readme.txt file describing the issues, any troubleshooting steps etc. This should be saved in a folder associated with that feeder dataset. 

- Come ready with a backup device to swap out with failed devices that cannot be troubleshooted in the field and need to be brought back to the 'workshop'. 

- When saving output, use a standardised file name system that contains information about the location/treatment. I suggest all files start with the date and should be in the format year/month/day so they appear chronologically in your folders. Alternatively you may want them sorted by location/nestbox, so start the file name with that info (e.g. "NB01_220427)

**Data management**

- The best practice is to work off a single master database always. If you have multiple copies of different formats you're prone to errors accumulating after each database is created, and forgetting which database was filtered in which way. 
Deviations from this are justifiable if you want your database to be organised according to site/nest box, in which case you are working from subsets of master data. Just be clear to label these as the master data files and always pull from these when running analyses or generating larger datasets. 

- Option 1: Wait for all data to come in and create a single database file when all files are available
- Option 2: Create a master database as each file comes in throughout the field season. This option is idea because you are likely going to need to analyse data as the experiment is happening, otherwise you are doing an experiment "blind" and you may detect issues that can be corrected at the time. 

In both cases, and especially in Option 2, there is a risk that you accidentally duplicate datasets if you merge it with file containing multiple datasets from different dates. *It is crucial that you keep a record of the code and the files imported so you can error check*. As we work through examples you will see just how important this is and why we will be using R Markdown and using the knit function each time data is imported and master datasets are generated. 

Another option is to create an R function. This means you specify arguments (e.g. file names, dataframes) at the top of the function, rather than editing multiple lines of code to accommodate the appropriate files/dataframes. The latter can lead to errors if you don't update one or more of the dataframe or file names accordingly. 

## 2.2 Importing RFID data and generating master database

### 2.2.1 working directory and files
# Imagine you have collected data from three RFID feeders deployed in the field. When you save the data from the SD card, you save it according to the date you collected it (YYMMDD), and the feeder ID (in this case F01, F02, F03)

```{r}
#set working directory so R knows where to find and save data
setwd("F:/RWorkspace/GitHub/RFID-workshop/data/feederData")

#specify the working directly as the object "path"

path<-"F:/RWorkspace/GitHub/RFID-workshop/data/feederData"

#use the function list.dirs to see all the folders in your directory
list.dirs(path, full.names = TRUE, recursive = TRUE)

#now use the function list.files to see what files are in that folder and all subfolders (recursive=TRUE). 
list.files(path, pattern=NULL, all.files=FALSE,
    full.names=FALSE, recursive = TRUE)

#now use the function to look into one of the subfolders

path2<-"F:/RWorkspace/GitHub/RFID-workshop/data/feederData/F01_220206"
list.files(path2, pattern=NULL, all.files=FALSE,
    full.names=FALSE, recursive = TRUE)

```

# what you are seeing are a number of files that start with a alphanumberic code, followed by two letters. "C1935" refers to the feeder's hardware ID code. This can never change. The last two letters refer to the output file type. For example, FD refers to "feeder door" and has information about whether the servo door opened (o) or stayed closed (c) upon detection of a bird. For our purposes, we will focus on the RT files only. 


### 2.2.2 Viewing files and preparing for compiling them into a single dataframe

```{r}

#the files are text files so you need to use a function that calls .txt. files

setwd(path2) #since we already created path2 as folder F01_220206, lets start with that.
getwd() #double check you are now in the appropriate working directory

# Call the RT file into your environment and call it df1 (dataframe 1)
df1<-read.delim("C1935RT.txt", header=TRUE)

names(df1) #see the column headers
head(df1) # see the first few rows and headers

```

# what you are seeing are time stamped events every time the strain gauge perch is triggered. If there is an associated RFID tag read, it appears under the column header "TagID_hex". 
# You can see the ID is c1935 which matches our folder name. Dur Clks Freq and Edges refer to some RFID parameters, which may be useful if there are any issues with detecting tags (there are lots of events without tags). 
# the most important headers for downstream analyses are Date, Hmsec, ID and TagID_hex. But we will keep all headers.
# you should notice that although we have the ID of the feeder, that does not provide us with any information about where the feeder was located in our experimental design which is FUNDAMENTAL to analyses. If you are to compile a dataframe that contains data from multiple different feeders, you must know which data comes from which feeder. 

### 2.2.3 Adding a column to indicate which feeder your data belongs to 

```{r}

#first look at your df1 in your global environment. It should say 337 obs. (observations) of 15 variables. 

df1<-cbind(df1, feeder='F01') #add a column named feeder and have all the values as F01

#now df1 should say 16 variables. But do a sanity check:

head(df1)

#we can repeat this for more feeders. We need to specify a new path and working directory, lets do that for feeder 2, with the same date. 

path3<-"F:/RWorkspace/GitHub/RFID-workshop/data/feederData/F02_220206"
setwd(path3)

#double check you are in the correct directory 
getwd()
#if you want to check the file names: 

list.files(path3, pattern=NULL, all.files=FALSE,
    full.names=FALSE, recursive = TRUE)

df2<-read.delim("C1931RT.txt", header=TRUE)

names(df2) #see the column headers
head(df2) # see the first few rows and headers

#this file has the same headers as df1. Lets add the feeder column and values. 

df2<-cbind(df2, feeder='F02') #add a column named feeder and have all the values as F02
names(df2) #see the column headers
head(df2) # see the first few rows and headers

#we can repeat this for the 3rd feeder too. We can also skip having to look in the directory by doing the following:

path4<-"F:/RWorkspace/GitHub/RFID-workshop/data/feederData/F03_220206"
setwd(path4)

RTfile<-list.files(path4, pattern = "RT")
df3<-lapply(RTfile, read.delim) #this will appear as a list in your environment
df3<-as.data.frame(df3) #turn it into a dataframe
head(df3)
df3<-cbind(df3, feeder='F03') #add a column named feeder and have all the values as F03

```

### 2.2.4 bind rows from different data frames into a single dataframes
```{r}
#Because you have now indicated which feeder each line of data comes from, you can safely combine all dataframes into one. They all have the same number of headers, and the headers are spelled the same, so this can be done without any additional changes.

d220206<-bind_rows(df1,df2,df3)  #I have named this according to the date of the folder these files came from. 

#you should now see d220206 in your environment and there should be 1526 observations

377+780+369  #the combined number of observations from df1, df2 and df3 =1526, which is expected. 

#you should now be able to do this for the other folder dated 220206. Because you may use a similar naming system, or copy and paste the code above and edit the code, it is good practice to remove the dataframes that are no longer needed. 

rm(df1,df2,df3) #this should remove them from your environment. 


```

### **2.3 EXERCISE** 
There are three more files in the folder that come from different feeders that need to be added to the master database.

Make sure to 

- add the feeder name column

- save a new Master database with **THE DATE OF THE LAST SET OF FILES YYMMDD**

```{r}

#if you use the same naming system as before, you will then end up with a dataframe named d220209. 

#bind rows for your dataframes from different dates

dfinal<-bind_rows(d220206,d220209)  #the order of the dfs as arguments will determine the order in which they appear in the dataframe. You can change this, but you could here choose the most contemporary date to come second. 
```


### 2.4.1 Saving your work and returning to it later
```{r}

#by default, R will save to your current working directory. So lets change it to a higher directory than we are currently in. Otherwise it may be hard to find which subfolder to save into. You could also create a folder specifically for saving into. 

setwd("F:/RWorkspace/GitHub/RFID-workshop/data/feederData")

write.table(dfinal, file = "Masterdf_220209.txt",sep="\t",row.names=FALSE)  #we are saving the dataframe called dfinal as a txt file into our working directory 

#you should be able to view this using the following code: 
list.dirs(path = "F:/RWorkspace/GitHub/RFID-workshop/data/feederData", full.names = TRUE, recursive = FALSE) #notice that recursive has been changed to F as we only want to see what is in that particular folder, not subfolders. 

#Save your R script, and if using github, update the current branch, generate a pull request and merge to your main branch. 
#when you close R, it may ask you if you want to save the workspace image. This means you can open that saved file with the data and values from your global environment as you left off. You can select no if that's not relevant. But if you were in the middle of something and needed to stop, that is a useful option. 

#If you would like to clear your global environment entirely. 
rm(list = ls())

#load your last working master dataframe to continue to add more incoming data, following the same steps above for new RT files. 

#if you have closed R, you will need to specify the working directory
setwd("F:/RWorkspace/GitHub/RFID-workshop/data/feederData")
masterdf<-read.delim("Masterdf_220209.txt", header=TRUE)
head(masterdf)

#add a new column named "feeder" with information about what feeder it comes from 
df1<-cbind(df1, feeder='feeder01')  
names(df1)
df2<-cbind(df2, feeder='feeder01')
names(df2)  
#you can also look at your global environment and check there are now 4 variables
df3<-cbind(df3, feeder='feeder02')
df4<-cbind(df4, feeder='feeder02')
#now you can join these into a single dataframe

masterdf<-dplyr::bind_rows(df1,df2,df3,df4) 

#this dataframe should have a total observations that is the sum of all 4 dfs, and 4 variables
#now save your master dataframe

write.table(masterdf, file = "200122MasterDatabase_feeders_2020FieldSeason.txt",sep="\t",row.names=FALSE) 

#finally, lets clear the global environment so we don't have any conflicts with the next steps 
rm(list = ls(all.names = TRUE))
```

### Use R Markdown to keep track of your data importing and saving 
Perhaps in the previous exercise you saved time by cutting and pasting previous code and changing the file names
What if you changed the file name you saved to, but not the file name you uploaded, or vice versa? 
What if you uploaded more data to merge it with an existing dataframe, and instead of copying and pasting your code (your document is getting rather large now), you decided to just write over previous code. 
The latter is arguably not good practice, best to keep a record of every code you run. But there's still the possibility that along a long string of repetitive code, you lose track of what was done when. 
R markdown is an excellent tool for keeping track of what you have done and sharing your code with others. 
As you become more familiar with R you will also be able to write your own functions that will also minimise the chance of code errors/typos. 

- In R studio go to File>New File> R Markdown...

- Input a title and click ok. 

- Delete all the default text except the title

- On the top right hand corner of the R markdown window is a green sqare with a plus sign and "c". Click that arrow and chose r script

- You can now write your r script in this gray area
- Use the "#" below r script to leave yourself notes
- write outside of the r script for headings or any other detail you want. 
- click the Knit button on the top left hand side of the R markdown window and it will produce a document and save it to your working directory. 

Additional resources for independent discovery of concepts and code: 
- google
- stack exchange
- chatgpt
- [R Markdown Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)

### **2.5 EXERCISE** 

Using the code you produced earlier, create a short R Markdown file and knit it. 

# END OF 2. RFID Tutorial: Introduction to RFID use and data handling 

```{r}
sessionInfo()
```

